{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensors — Hands-On Tutorial\n",
    "\n",
    "**Month 2, Week 1** — Sequence Models\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch. Think of them as n-dimensional arrays that can run on GPU.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Creating tensors (multiple ways)\n",
    "2. Tensor attributes (shape, dtype, device)\n",
    "3. Operations (math, reshaping, indexing)\n",
    "4. GPU/MPS acceleration\n",
    "5. Preview: connection to autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Creating Tensors\n",
    "\n",
    "### From Python data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From list:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# From a Python list\n",
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "t1 = torch.tensor(data)\n",
    "print(\"From list:\")\n",
    "print(t1)\n",
    "print(f\"Shape: {t1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From NumPy:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n",
      "\n",
      "After modifying numpy: 999.0\n"
     ]
    }
   ],
   "source": [
    "# From NumPy (shares memory by default!)\n",
    "np_array = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "t2 = torch.from_numpy(np_array)\n",
    "print(\"From NumPy:\")\n",
    "print(t2)\n",
    "\n",
    "# Modifying numpy changes the tensor!\n",
    "np_array[0, 0] = 999\n",
    "print(f\"\\nAfter modifying numpy: {t2[0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Ones:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Zeros and ones\n",
    "zeros = torch.zeros(2, 3)\n",
    "ones = torch.ones(2, 3)\n",
    "print(f\"Zeros:\\n{zeros}\")\n",
    "print(f\"\\nOnes:\\n{ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform [0,1):\n",
      "tensor([[0.3893, 0.9748, 0.9735],\n",
      "        [0.4535, 0.9762, 0.4830]])\n",
      "\n",
      "Normal:\n",
      "tensor([[ 1.8515, -0.0935,  0.7531],\n",
      "        [-0.4094, -0.1737, -1.6308]])\n",
      "\n",
      "Integers [0,10):\n",
      "tensor([[9, 5, 7],\n",
      "        [7, 2, 7]])\n"
     ]
    }
   ],
   "source": [
    "# Random tensors (very common for initializing weights)\n",
    "rand_uniform = torch.rand(2, 3)      # Uniform [0, 1)\n",
    "rand_normal = torch.randn(2, 3)      # Normal (mean=0, std=1)\n",
    "rand_int = torch.randint(0, 10, (2, 3))  # Integers [0, 10)\n",
    "\n",
    "print(f\"Uniform [0,1):\\n{rand_uniform}\")\n",
    "print(f\"\\nNormal:\\n{rand_normal}\")\n",
    "print(f\"\\nIntegers [0,10):\\n{rand_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: torch.Size([2, 2]), dtype=torch.float32\n",
      "zeros_like:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Like another tensor (same shape, dtype, device)\n",
    "template = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "zeros_like = torch.zeros_like(template)\n",
    "rand_like = torch.rand_like(template)\n",
    "\n",
    "print(f\"Template: {template.shape}, dtype={template.dtype}\")\n",
    "print(f\"zeros_like:\\n{zeros_like}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange(0, 10, 2): tensor([0, 2, 4, 6, 8])\n",
      "linspace(0, 1, 5): tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Sequences\n",
    "arange = torch.arange(0, 10, 2)  # start, end, step\n",
    "linspace = torch.linspace(0, 1, 5)  # start, end, num_points\n",
    "\n",
    "print(f\"arange(0, 10, 2): {arange}\")\n",
    "print(f\"linspace(0, 1, 5): {linspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Tensor Attributes\n",
    "\n",
    "Every tensor has three key attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4, 5])\n",
      "Dtype: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3, 4, 5)\n",
    "\n",
    "print(f\"Shape: {t.shape}\")       # Dimensions\n",
    "print(f\"Dtype: {t.dtype}\")       # Data type\n",
    "print(f\"Device: {t.device}\")     # CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32: torch.float32\n",
      "float16: torch.float16\n",
      "int64: torch.int64\n",
      "bool: torch.bool\n"
     ]
    }
   ],
   "source": [
    "# Common dtypes for deep learning\n",
    "float32 = torch.tensor([1.0], dtype=torch.float32)  # Default, most common\n",
    "float16 = torch.tensor([1.0], dtype=torch.float16)  # Half precision (faster on GPU)\n",
    "int64 = torch.tensor([1], dtype=torch.int64)        # Labels/indices\n",
    "bool_t = torch.tensor([True, False], dtype=torch.bool)  # Masks\n",
    "\n",
    "print(f\"float32: {float32.dtype}\")\n",
    "print(f\"float16: {float16.dtype}\")\n",
    "print(f\"int64: {int64.dtype}\")\n",
    "print(f\"bool: {bool_t.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Basic Operations\n",
    "\n",
    "### Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "\n",
      "a * b (element-wise):\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "\n",
      "a ** 2:\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# Element-wise operations\n",
    "print(f\"a + b:\\n{a + b}\")\n",
    "print(f\"\\na * b (element-wise):\\n{a * b}\")\n",
    "print(f\"\\na ** 2:\\n{a ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a @ b (matrix multiply):\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "\n",
      "All equal: True\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication (crucial for neural networks!)\n",
    "# Three equivalent ways:\n",
    "result1 = a @ b\n",
    "result2 = torch.matmul(a, b)\n",
    "result3 = a.matmul(b)\n",
    "\n",
    "print(f\"a @ b (matrix multiply):\\n{result1}\")\n",
    "print(f\"\\nAll equal: {torch.equal(result1, result2) and torch.equal(result2, result3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Sum all: 21.0\n",
      "Sum per row (dim=1): tensor([ 6., 15.])\n",
      "Sum per column (dim=0): tensor([5., 7., 9.])\n",
      "Mean: 3.5\n",
      "Max: 6.0\n",
      "Argmax: 5\n"
     ]
    }
   ],
   "source": [
    "# Aggregations\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "print(f\"Tensor:\\n{t}\")\n",
    "print(f\"\\nSum all: {t.sum()}\")\n",
    "print(f\"Sum per row (dim=1): {t.sum(dim=1)}\")\n",
    "print(f\"Sum per column (dim=0): {t.sum(dim=0)}\")\n",
    "print(f\"Mean: {t.mean()}\")\n",
    "print(f\"Max: {t.max()}\")\n",
    "print(f\"Argmax: {t.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "Shape: torch.Size([12])\n",
      "\n",
      "Reshaped to (3, 4):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "Reshaped to (2, -1):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(12)\n",
    "print(f\"Original: {t}\")\n",
    "print(f\"Shape: {t.shape}\")\n",
    "\n",
    "# Reshape (total elements must match)\n",
    "reshaped = t.reshape(3, 4)\n",
    "print(f\"\\nReshaped to (3, 4):\\n{reshaped}\")\n",
    "\n",
    "# Use -1 to infer dimension\n",
    "auto_reshaped = t.reshape(2, -1)  # -1 becomes 6\n",
    "print(f\"\\nReshaped to (2, -1):\\n{auto_reshaped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Flattened: tensor([0, 1, 2, 3, 4, 5])\n",
      "\n",
      "Original shape: torch.Size([3])\n",
      "unsqueeze(0) shape: torch.Size([1, 3])\n",
      "unsqueeze(1) shape: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# view vs reshape: view requires contiguous memory, reshape is more flexible\n",
    "t = torch.arange(6).reshape(2, 3)\n",
    "print(f\"Original:\\n{t}\")\n",
    "\n",
    "# Flatten (very common before fully connected layers)\n",
    "flattened = t.flatten()\n",
    "print(f\"\\nFlattened: {flattened}\")\n",
    "\n",
    "# Squeeze/unsqueeze (add/remove dimensions of size 1)\n",
    "t = torch.tensor([1, 2, 3])\n",
    "print(f\"\\nOriginal shape: {t.shape}\")\n",
    "print(f\"unsqueeze(0) shape: {t.unsqueeze(0).shape}\")  # Add batch dim\n",
    "print(f\"unsqueeze(1) shape: {t.unsqueeze(1).shape}\")  # Add feature dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "t[0]: tensor([0, 1, 2, 3])\n",
      "t[0, 0]: 0\n",
      "t[:, 0]: tensor([0, 4, 8])\n",
      "t[1:, 1:3]:\n",
      "tensor([[ 5,  6],\n",
      "        [ 9, 10]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Tensor:\\n{t}\")\n",
    "\n",
    "# Standard indexing (like NumPy)\n",
    "print(f\"\\nt[0]: {t[0]}\")\n",
    "print(f\"t[0, 0]: {t[0, 0]}\")\n",
    "print(f\"t[:, 0]: {t[:, 0]}\")\n",
    "print(f\"t[1:, 1:3]:\\n{t[1:, 1:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([-1.1492,  0.1502, -0.8677,  2.5607, -0.7654])\n",
      "Positive mask: tensor([False,  True, False,  True, False])\n",
      "Positive values: tensor([0.1502, 2.5607])\n"
     ]
    }
   ],
   "source": [
    "# Boolean indexing (for masking)\n",
    "t = torch.randn(5)\n",
    "print(f\"Tensor: {t}\")\n",
    "print(f\"Positive mask: {t > 0}\")\n",
    "print(f\"Positive values: {t[t > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. GPU/MPS Acceleration\n",
    "\n",
    "PyTorch can run on:\n",
    "- `cpu` — Default\n",
    "- `cuda` — NVIDIA GPUs\n",
    "- `mps` — Apple Silicon (M1/M2/M3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "MPS available: True\n",
      "\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Choose best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU tensor device: cpu\n",
      "GPU tensor device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Move tensor to device\n",
    "t_cpu = torch.randn(1000, 1000)\n",
    "t_gpu = t_cpu.to(device)\n",
    "\n",
    "print(f\"CPU tensor device: {t_cpu.device}\")\n",
    "print(f\"GPU tensor device: {t_gpu.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created on device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Create directly on device\n",
    "t_direct = torch.randn(1000, 1000, device=device)\n",
    "print(f\"Created on device: {t_direct.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU matmul: 0.0070 seconds\n",
      "GPU matmul: 0.0047 seconds\n",
      "Speedup: 1.5x\n"
     ]
    }
   ],
   "source": [
    "# Speed comparison: matrix multiplication\n",
    "import time\n",
    "\n",
    "size = 2000\n",
    "a_cpu = torch.randn(size, size)\n",
    "b_cpu = torch.randn(size, size)\n",
    "\n",
    "# CPU timing\n",
    "start = time.time()\n",
    "c_cpu = a_cpu @ b_cpu\n",
    "cpu_time = time.time() - start\n",
    "print(f\"CPU matmul: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# GPU timing (if available)\n",
    "if device.type != \"cpu\":\n",
    "    a_gpu = a_cpu.to(device)\n",
    "    b_gpu = b_cpu.to(device)\n",
    "    \n",
    "    # Warm up GPU\n",
    "    _ = a_gpu @ b_gpu\n",
    "    if device.type == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    c_gpu = a_gpu @ b_gpu\n",
    "    if device.type == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    gpu_time = time.time() - start\n",
    "    \n",
    "    print(f\"GPU matmul: {gpu_time:.4f} seconds\")\n",
    "    print(f\"Speedup: {cpu_time / gpu_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Preview: Autograd Connection\n",
    "\n",
    "Tomorrow we'll dive deep into autograd. Here's the key insight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "y = x² + 3x = 10.0\n",
      "dy/dx = 2x + 3 = 7.0\n",
      "Expected: 2*2 + 3 = 7\n"
     ]
    }
   ],
   "source": [
    "# requires_grad=True tells PyTorch to track operations for gradients\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Forward pass: compute y = x^2 + 3x\n",
    "y = x ** 2 + 3 * x\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = x² + 3x = {y.item()}\")\n",
    "\n",
    "# Backward pass: compute dy/dx\n",
    "y.backward()\n",
    "print(f\"dy/dx = 2x + 3 = {x.grad.item()}\")\n",
    "print(f\"Expected: 2*2 + 3 = 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This automatic differentiation is what makes PyTorch powerful for training neural networks. We'll explore it fully tomorrow.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these to solidify your understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Create a 3x3 identity matrix\n",
    "# Hint: torch.eye()\n",
    "\n",
    "identity = torch.eye(3)  # Your code here\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n",
      "Reshaped: torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Create a tensor of shape (2, 3, 4) filled with random values,\n",
    "# then reshape it to (6, 4)\n",
    "\n",
    "t = torch.randn([2, 3, 4])  # Your code here\n",
    "reshaped = t.reshape(6, -1)  # Your code here\n",
    "print(f\"Original shape: {t.shape}\")\n",
    "print(f\"Reshaped: {reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result shape: torch.Size([100, 100])\n",
      "Result device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Given two matrices, compute their matrix product on GPU (if available)\n",
    "\n",
    "a = torch.randn(100, 50)\n",
    "b = torch.randn(50, 100)\n",
    "\n",
    "# Move to device and multiply\n",
    "result = a.to(device) @ b.to(device)  # Your code here\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result device: {result.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([1., 5., 3., 9., 2.])\n",
      "Normalized: tensor([-0.9487,  0.3162, -0.3162,  1.5811, -0.6325])\n",
      "Mean: 0.000000\n",
      "Std: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Normalize a tensor to have mean=0 and std=1\n",
    "# Formula: (x - mean) / std\n",
    "\n",
    "t = torch.tensor([1.0, 5.0, 3.0, 9.0, 2.0])\n",
    "normalized = (t - t.mean()) / t.std()  # Your code here\n",
    "\n",
    "print(f\"Original: {t}\")\n",
    "print(f\"Normalized: {normalized}\")\n",
    "print(f\"Mean: {normalized.mean():.6f}\")\n",
    "print(f\"Std: {normalized.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Functions |\n",
    "|---------|---------------|\n",
    "| Creation | `tensor()`, `zeros()`, `ones()`, `rand()`, `randn()` |\n",
    "| Attributes | `.shape`, `.dtype`, `.device` |\n",
    "| Math | `+`, `*`, `@`, `.sum()`, `.mean()` |\n",
    "| Reshaping | `.reshape()`, `.flatten()`, `.unsqueeze()` |\n",
    "| GPU | `.to(device)`, `device=` parameter |\n",
    "\n",
    "## Tomorrow\n",
    "\n",
    "**Autograd deep dive** — How PyTorch computes gradients automatically, which is the foundation of training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
